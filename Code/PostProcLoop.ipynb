{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read in all of the relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd  #Pandas is a nice package for data reading/selection\n",
    "import math\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import ellipses as el\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "from IPython.display import display\n",
    "import sys\n",
    "import pickle\n",
    "import seaborn\n",
    "seaborn.set_style('ticks')\n",
    "%matplotlib inline\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "## for Palatino and other serif fonts use:\n",
    "#rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for postprocessing the large numbers of simulations we run with the metapopulations code. It takes a list of file names, reads in those simulations, then can calculate various quantities from those simulations to generate output figures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cart2pol(x, y):\n",
    "    rho = np.sqrt(x**2 + y**2)\n",
    "    phi = np.arctan2(y, x)\n",
    "    return(rho, phi)\n",
    "\n",
    "def pol2cart(rho, phi):\n",
    "    x = rho * np.cos(phi)\n",
    "    y = rho * np.sin(phi)\n",
    "    return(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Codes for transforming the timeseries to polar coordinates, normalizing them, and calculating the area of a complex\n",
    "#hull that encircles them.\n",
    "\n",
    "def meanNormalize(data):\n",
    "    fold = 24\n",
    "    nobs = len(data)\n",
    "    dates = np.linspace(0,nobs-1,nobs) \n",
    "    dates = (dates)%fold     #A year is 24 timesteps, in this code. For whatever reason.\n",
    "    nyear = sum(dates==fold-1)\n",
    "    theta = 2.*np.pi*((dates)/float(fold-1))\n",
    "    npatch = np.shape(data)[1]  \n",
    "    thresh = 1.\n",
    "    data_summed = np.sum(data,axis=1)\n",
    "    data_summed[data_summed<=thresh] = 0.   #Trying to ignore the 'virgin introduction spikes'\n",
    "    data_summed = data_summed/float(npatch)\n",
    "    data_norm = np.zeros([nobs]) \n",
    "    '''\n",
    "    nhigh = 0\n",
    "    for i in range(nyear):\n",
    "        nhigh = np.max(data_summed[i*24:(i+1)*24])\n",
    "        if nhigh ==0.:\n",
    "            nhigh = 1.\n",
    "        data_norm[i*24:(i+1)*24] = data_summed[i*24:(i+1)*24]/float(nhigh)   \n",
    "    '''\n",
    "    \n",
    "    nhigh = 0 \n",
    "    k = 0\n",
    "    for d in dates:\n",
    "        #This loop looks forward/backward 12 timesteps and finds the maximum in that window.\n",
    "        if k<fold/2:\n",
    "            nhigh = np.max(data_summed[0:k+fold/2])\n",
    "        elif k>nobs-fold/2:\n",
    "            nhigh = np.max(data_summed[k-fold/2:])\n",
    "        else:\n",
    "            nhigh = np.max(data_summed[k-fold/2:k+fold/2])    \n",
    "        if nhigh==0.:\n",
    "            nhigh += 1.5      #Don't divide by zero.\n",
    "        data_norm[k] = data_summed[k]/float(nhigh)\n",
    "        if nhigh==1.:   #Only one infection in this window - i.e. probably just a virgin intro. burst\n",
    "            data_norm[k] = 0.\n",
    "        k += 1\n",
    "    \n",
    "    return data_norm\n",
    "\n",
    "def Normalize(data):\n",
    "    nobs = len(data)      #How many 'observations'? (i.e. timesteps)\n",
    "    dates = np.linspace(0,nobs-1,nobs) \n",
    "    dates = (dates)%24     #A year is 24 timesteps, in this code. For whatever reason.\n",
    "    nyear = sum(dates==23)\n",
    "    theta = 2.*np.pi*((dates)/23.)\n",
    "    npatch = np.shape(data)[1]  \n",
    "    data_norm = np.zeros([nobs,npatch])\n",
    "    #Looks over the calendar year:\n",
    "    for p in range(npatch):\n",
    "        nhigh = 0\n",
    "        for i in range(nyear):\n",
    "            nhigh = np.max(data[i*24:(i+1)*24,p])\n",
    "            if nhigh ==0.:\n",
    "                nhigh = 1.\n",
    "            data_norm[i*24:(i+1)*24,p] = data[i*24:(i+1)*24,p]/float(nhigh)       \n",
    "        \n",
    "    '''\n",
    "    k = 0\n",
    "    for d in dates:\n",
    "        #This loop looks forward/backward 12 timesteps and finds the maximum in that window.\n",
    "        if k<12:\n",
    "            nhigh = np.max(data[0:k+12,p])\n",
    "        elif k>nobs-12:\n",
    "            nhigh = np.max(data[k-12:,p])\n",
    "        else:\n",
    "            nhigh = np.max(data[k-12:k+12,p])    \n",
    "        if nhigh==0.:\n",
    "            nhigh += 1.5      #Don't divide by zero.\n",
    "        data_norm[k,p] = data[k,p]/float(nhigh)\n",
    "        if nhigh==1.:   #Only one infection in this window - i.e. probably just a virgin intro. burst\n",
    "            data_norm[k,p] = 0.\n",
    "        k += 1\n",
    "        '''\n",
    "    return data_norm\n",
    "\n",
    "def AreaCalc(data,theta,tstart=0):\n",
    "    npatch = np.shape(data)[1] \n",
    "    area = []\n",
    "    for i in range(npatch):\n",
    "        thetafit = theta[tstart:]\n",
    "        Ifit = data[tstart:,i]\n",
    "        cartcoords = pol2cart(Ifit,thetafit)\n",
    "        points = np.array(cartcoords)\n",
    "        points = points.T\n",
    "        if len(data)>1 and np.sum(data)>0.:\n",
    "            hull = ConvexHull(points)\n",
    "            area.append(hull.volume)\n",
    "        if np.sum(data)==0.:\n",
    "            area.append(np.pi)\n",
    "    return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Code for fitting an ellipse to the polar timeseries using an MCMC. The mean of the fitted eccentricity is \n",
    "#the reported statistic.\n",
    "\n",
    "#Likelihood\n",
    "def eLike(p,t,d):\n",
    "    fac = 2.   #factor for penalizing outside the ellipse higher than inside.\n",
    "    \n",
    "    e = p[0]\n",
    "    a = p[1]\n",
    "    phi = p[2]\n",
    "\n",
    "    recc = a*(1.-e*e)/(1.-e*np.cos(t-phi)) #radius of the ellipse at phi\n",
    "    delta = (recc-d)\n",
    "    delta[delta<0.] *= fac  #apply factor to points that are outside of ellipse\n",
    "    dmask = d>0.\n",
    "    \n",
    "    if np.sum(d)==0.:\n",
    "        p[0] = 0.   #If there are no cases, the eccentricity is zero.\n",
    "        p[1] = 0.25\n",
    "\n",
    "    return -np.sum(delta[dmask]**2)  #return the sum of the differences squared (chi-squared likelihood basically)\n",
    "\n",
    "\n",
    "#Jump proposals for the MCMC. Very unsophisticated but they work just fine.\n",
    "def bigstep(x):\n",
    "    delta = np.random.normal(loc=0.,scale=0.5,size=np.shape(x))\n",
    "    y = x + delta\n",
    "    return y\n",
    "\n",
    "def smallstep(x):\n",
    "    delta = np.random.normal(loc=0.,scale=0.05,size=np.shape(x))\n",
    "    y = x + delta\n",
    "    return y\n",
    "\n",
    "def tinystep(x):\n",
    "    delta = np.random.normal(loc=0.,scale=0.005,size=np.shape(x))\n",
    "    y = x + delta\n",
    "    return y\n",
    "\n",
    "\n",
    "def ebigstep(x):\n",
    "    delta = np.random.normal(loc=0.,scale=0.5,size=np.shape(x))\n",
    "    y = x + delta\n",
    "    return y\n",
    "\n",
    "def esmallstep(x):\n",
    "    delta = np.random.normal(loc=0.,scale=0.05,size=np.shape(x))\n",
    "    y = x + delta\n",
    "    return y\n",
    "\n",
    "def etinystep(x):\n",
    "    delta = np.random.normal(loc=0.,scale=0.005,size=np.shape(x))\n",
    "    y = x + delta\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Take a list of files to generate an output for that list. Will be nxm long, where n and m are the number of sims\n",
    "#for each of the parameters you've looped over (need to tell it n and m)You'll need to set up the filenames so that \n",
    "#they actually go in the order you want. \n",
    "#to make filelist: ls -1 *.csv | sort -t'_' -n -k2 > filelist.txt\n",
    "filenames = pd.read_csv('../Sims/test2/filelist.txt',delim_whitespace=True,header=None)\n",
    "n = 5  #points along first parameter\n",
    "m = 5  #points along second parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Getting the file names in a workable format\n",
    "filemat = filenames.values\n",
    "filemat = filemat.flatten()\n",
    "npoint = len(filemat)/4\n",
    "filemat = filemat.reshape([npoint,4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#'toplot' is the variable that you'll be calculating in order to generate a color map. \n",
    "# options: nigh, Ipercent, ellipse, meanellipse, ecc, meanecc ('ellipse' really gives the area of the convex hull.\n",
    "#'ecc' gives the eccentricity of an ellipse fitted through the data.)\n",
    "#\n",
    "toplot = 'ecc'  \n",
    "#set up a matrix to hold the values of this variable:\n",
    "plotmat = np.zeros([n,m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfiles_subset = []\\nfor i in range(n):\\n    files_subset.append(filemat[:,n*m*i:n*m*(i+1)])\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select the subset of files you're going to work with (mostly for testing purposes):\n",
    "'''\n",
    "files_subset = []\n",
    "for i in range(n):\n",
    "    files_subset.append(filemat[:,n*m*i:n*m*(i+1)])\n",
    "'''\n",
    "#files_subset now contains nxm (x4, since there are I,S,R,and V files for each sim) \n",
    "#files for each of 10 different vaccination variance levels. If you want to make a grid looping over vacc. variance,\n",
    "#you'll have to change the code quite a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 4)\n",
      "cases_75_vaxvar0.5_popvar0.7_pop5000.0_0.csv\n"
     ]
    }
   ],
   "source": [
    "#Select all files with the same vacc. variance.\n",
    "#files = files_subset[4]\n",
    "choose = 4 #which vacc. variance do you want to look at? Starts at 1, not 0.\n",
    "files = filemat[n*m*(choose-1):n*m*choose,:]\n",
    "print np.shape(files)\n",
    "print files[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "cases_75_vaxvar0.5_popvar0.7_pop5000.0_0.csv\n",
      "0 0 0\n",
      "0 0 50\n",
      "0 0 100\n",
      "0 0 150\n",
      "0 0 200\n"
     ]
    }
   ],
   "source": [
    "#This loop reads through all of the files and calculates the output variable, storing it in the plotmat matrix.\n",
    "for i in range(n):\n",
    "    print i\n",
    "    for j in range(m):\n",
    "        #Read in data file\n",
    "        filenum = i*n+j%m\n",
    "        print files[filenum,0]\n",
    "        \n",
    "\n",
    "        Ifile = pd.read_csv('../Sims/test2/'+files[filenum,0], delim_whitespace=True,header=0)\n",
    "        Sfile = pd.read_csv('../Sims/test2/'+files[filenum,1], delim_whitespace=True,header=0)\n",
    "        Rfile = pd.read_csv('../Sims/test2/'+files[filenum,2], delim_whitespace=True, header=0)\n",
    "        Vfile = pd.read_csv('../Sims/test2/'+files[filenum,3], delim_whitespace=True,header=0)\n",
    "        \n",
    "        Idata_all = Ifile.values\n",
    "        Sdata_all = Sfile.values\n",
    "        Rdata_all = Rfile.values\n",
    "        Vdata_all = Vfile.values\n",
    "                \n",
    "        Idata_all = Idata_all.astype(float)\n",
    "        Sdata_all = Sdata_all.astype(float)\n",
    "        Rdata_all = Rdata_all.astype(float)\n",
    "        Vdata_all = Vdata_all.astype(float)\n",
    "        \n",
    "        tsteps = len(Idata_all[:,0])\n",
    "        npatch = len(Idata_all[0,:])\n",
    "        \n",
    "        burnin = 0.6*len(Idata_all)\n",
    "        burnin = int(burnin)\n",
    "        \n",
    "        Idata = Idata_all[burnin:,:]\n",
    "        Sdata = Sdata_all[burnin:,:]\n",
    "        Rdata = Rdata_all[burnin:,:]\n",
    "        Vdata = Vdata_all[burnin:,:]\n",
    "        \n",
    "        '''print j\n",
    "        if (j-5)%10==0:\n",
    "            print files[0,filenum]\n",
    "            plt.plot(Idata)\n",
    "            '''\n",
    "        \n",
    "        #Outbreaks are identified as any string of more than one time-step during which I>0 in a cell.\n",
    "        if toplot=='Ipercent': #percentage of patches infected over full timeseries\n",
    "            outsize = np.zeros(npatch)\n",
    "            k = 1\n",
    "            while k<(tsteps-burnin):\n",
    "                for r in range(npatch):\n",
    "                    if Idata[k,r] > 0.:\n",
    "                        if Idata[k-1,r] > 0.:\n",
    "                            outsize[r] += Idata[k,r]\n",
    "                k += 1\n",
    "\n",
    "            totinf = sum(outsize)\n",
    "            totpop = Idata+Sdata+Rdata+Vdata\n",
    "            totpop = sum(totpop)\n",
    "            fracinf = outsize/totpop\n",
    "            print np.shape(outsize)\n",
    "\n",
    "            plotmat[i,j] = max(fracinf)\n",
    "\n",
    "        if toplot=='nhigh': #number of timesteps in which there is infection present (either by individual patch \n",
    "                            #or over the entire metapopulation)\n",
    "            nhigh = 0\n",
    "            k = 0\n",
    "            while k<(tsteps-burnin):\n",
    "                Ifrac = Idata[k,:]/(Idata[k,:]+Sdata[k,:]+Rdata[k,:]+Vdata[k,:])\n",
    "                mask = Ifrac>=0.0\n",
    "                Ihigh = Ifrac[mask]\n",
    "                x = Ihigh*1.\n",
    "                nhigh += len(x)\n",
    "                k+=1\n",
    "            plotmat[i,j] = nhigh\n",
    "            \n",
    "        if toplot=='ellipse':   #average area of convex hull around each patch's timeseries in polar coordinates.\n",
    "            nobs = len(Idata)      #How many 'observations'? (i.e. timesteps)\n",
    "            dates = np.linspace(0,nobs-1,nobs) \n",
    "            dates = (dates)%24     #A year is 24 timesteps, in this code. For whatever reason.\n",
    "            theta = 2.*np.pi*((dates+1)/24.)\n",
    "            Idata_normed = Normalize(Idata)\n",
    "            Areas = AreaCalc(Idata_normed)\n",
    "            plotmat[i,j] = np.mean(Areas)\n",
    "            \n",
    "        if toplot=='meanellipse': #area of convex hull around sum of all patches in polar coordinates\n",
    "            nobs = len(Idata)      #How many 'observations'? (i.e. timesteps)\n",
    "            dates = np.linspace(0,nobs-1,nobs) \n",
    "            dates = (dates)%24     #A year is 24 timesteps, in this code. For whatever reason.\n",
    "            theta = 2.*np.pi*((dates)/(24.-1))\n",
    "            Idata_normed = meanNormalize(Idata)\n",
    "            Idata_normed = Idata_normed.reshape([len(Idata_normed),1])\n",
    "            Areas = AreaCalc(Idata_normed,theta,tstart=100)\n",
    "            plotmat[i,j] = np.mean(Areas)\n",
    "            \n",
    "        if toplot=='ecc': #eccentricity of ellipse fitted to polar data of timeseries sum of patches\n",
    "            Idata_norm = Normalize(Idata)\n",
    "            fold = 24\n",
    "            nobs = len(Idata_norm[:])\n",
    "            dates = np.linspace(0,nobs-1,nobs) \n",
    "            dates = (dates)%fold     #Wrap the data every fold steps\n",
    "            angle = 2.*np.pi*((dates)/float(fold-1))\n",
    "            \n",
    "            \n",
    "            \n",
    "            #select the nyear final years of data set\n",
    "            nyear = 15\n",
    "            t = angle[-nyear*24:]\n",
    "            e = []\n",
    "            npatch = np.shape(Idata)[1]\n",
    "            for p in range(npatch):\n",
    "                \n",
    "                if p%50==0:\n",
    "                    print i,j,p\n",
    "                \n",
    "                r = Idata_norm[-nyear*24:,p]\n",
    "                #starting point/likelihood for the train\n",
    "                p0 = np.array([0.,0.5,0.])\n",
    "                like0 = eLike(p0,t,r)\n",
    "\n",
    "                params = p0.copy()\n",
    "                Nstep = 5000  #number of steps for the MCMC\n",
    "\n",
    "                chain = []\n",
    "                chain.append(p0)\n",
    "\n",
    "                Lchain = []\n",
    "                Lchain.append(like0)\n",
    "                for step in range(Nstep):\n",
    "                    s = np.random.rand(1)\n",
    "                    if s>0.75:\n",
    "                        ptry = ebigstep(params)\n",
    "                    elif s>0.5:\n",
    "                        ptry = etinystep(params)\n",
    "                    else:\n",
    "                        ptry = esmallstep(params)\n",
    "\n",
    "                    #enforce periodic prior on phi:\n",
    "                    if ptry[2]>np.pi:\n",
    "                        ptry[2] -= np.pi\n",
    "\n",
    "                    if ptry[2]<0.:\n",
    "                        ptry[2] += np.pi\n",
    "                    like_try = eLike(ptry,t,r)\n",
    "                    #eccentricity is between 0 and 1:\n",
    "                    if ptry[0] >1.:\n",
    "                        like_try = -np.inf\n",
    "                    if ptry[0] <0.:\n",
    "                        like_try = -np.inf\n",
    "\n",
    "                    #Hastings ratio\n",
    "                    H = np.random.rand(1)\n",
    "                    h = np.exp(like_try - like0)\n",
    "\n",
    "                    if H<h:\n",
    "                        params = ptry\n",
    "                        like0 = like_try\n",
    "\n",
    "                    chain.append(params)\n",
    "                    Lchain.append(like0)\n",
    "\n",
    "                chain = np.array(chain)\n",
    "                chain = np.array(chain)\n",
    "                epatch = np.mean(chain[500:,0])\n",
    "                \n",
    "                e.append(epatch)\n",
    "            \n",
    "            e = np.array(e)\n",
    "            mask = e==0.\n",
    "            plotmat[i,j] = np.mean(e[~mask])          \n",
    "            \n",
    "        if toplot=='meanecc': #eccentricity of ellipse fitted to polar data of timeseries sum of patches\n",
    "            Idata_norm = meanNormalize(Idata)\n",
    "            fold = 24\n",
    "            nobs = len(Idata_norm[:])\n",
    "            dates = np.linspace(0,nobs-1,nobs) \n",
    "            dates = (dates)%fold     #Wrap the data every fold steps\n",
    "            angle = 2.*np.pi*((dates)/float(fold-1))\n",
    "            \n",
    "            #select the nyear final years of data set\n",
    "            nyear = 15\n",
    "            r = Idata_norm[-nyear*24:]\n",
    "            t = angle[-nyear*24:]\n",
    "            \n",
    "            #starting point/likelihood for the train\n",
    "            p0 = np.array([0.,0.5,0.])\n",
    "            like0 = eLike(p0,t,r)\n",
    "\n",
    "            params = p0.copy()\n",
    "            Nstep = 10000  #number of steps for the MCMC\n",
    "\n",
    "            chain = []\n",
    "            chain.append(p0)\n",
    "\n",
    "            Lchain = []\n",
    "            Lchain.append(like0)\n",
    "            for step in range(Nstep):\n",
    "                s = np.random.rand(1)\n",
    "                if s>0.75:\n",
    "                    ptry = ebigstep(params)\n",
    "                elif s>0.5:\n",
    "                    ptry = etinystep(params)\n",
    "                else:\n",
    "                    ptry = esmallstep(params)\n",
    "\n",
    "                #enforce periodic prior on phi:\n",
    "                if ptry[2]>np.pi:\n",
    "                    ptry[2] -= np.pi\n",
    "\n",
    "                if ptry[2]<0.:\n",
    "                    ptry[2] += np.pi\n",
    "                like_try = eLike(ptry,t,r)\n",
    "                #eccentricity is between 0 and 1:\n",
    "                if ptry[0] >1.:\n",
    "                    like_try = -np.inf\n",
    "                if ptry[0] <0.:\n",
    "                    like_try = -np.inf\n",
    "\n",
    "                #Hastings ratio\n",
    "                H = np.random.rand(1)\n",
    "                h = np.exp(like_try - like0)\n",
    "\n",
    "                if H<h:\n",
    "                    params = ptry\n",
    "                    like0 = like_try\n",
    "\n",
    "                chain.append(params)\n",
    "                Lchain.append(like0)\n",
    "\n",
    "            chain = np.array(chain)\n",
    "            chain = np.array(chain)\n",
    "            e = np.mean(chain[500:,0])\n",
    "            \n",
    "            plotmat[i,j] = e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print out a heatmap of the output variable.\n",
    "matrix = plotmat.copy();\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "cax = ax.imshow((matrix), interpolation='nearest', cmap='plasma',vmin=0.1,vmax=0.8)\n",
    "ax.set_xticks(np.arange(0,n,1))\n",
    "ax.set_yticks(np.arange(0,m,1))\n",
    "#ax.set_xticklabels(['50k','56k','61k','67k','72k','78k','83k','89k','94k','100k'],fontsize=12)\n",
    "#ax.set_yticklabels([1.0,3.1,5.2,7.3,9.4,11.5,13.7,15.8,17.9,20.],fontsize=12)\n",
    "ax.set_xlabel('Population Size',fontsize=15)\n",
    "ax.set_ylabel('Pop. Variance (\\%)',fontsize=15)\n",
    "\n",
    "# Add colorbar, make sure to specify tick locations to match desired ticklabels\n",
    "cbar = fig.colorbar(cax)\n",
    "#cbar.ax.set_yticklabels(['< -1', '0', '> 1'])  # vertically oriented colorbar\n",
    "fig.tight_layout()\n",
    "\n",
    "#plt.savefig('../Sims/alpha10c0.1/test.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.61002335 0.56057994 0.36180349 0.52376476 0.54500094]\n",
      " [0.47077    0.47907811 0.46460574 0.48426575 0.41867437]\n",
      " [0.64100064 0.64487385 0.63794215 0.61914594 0.59134686]\n",
      " [0.59629577 0.62530643 0.64765767 0.65007189 0.66519466]\n",
      " [0.64054732 0.63565668 0.63751002 0.65707736 0.66310443]]\n"
     ]
    }
   ],
   "source": [
    "print plotmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
